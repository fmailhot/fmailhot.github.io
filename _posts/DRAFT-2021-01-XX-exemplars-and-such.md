# memorization, analogy, and generalization in linguistic science
---

In _First Language, Vol. 40(5--6)_ Ambridge (2020) presents empirical and theoretical arguments for a "radical exemplar" approach to child language acquisition. He presents empirical and theoretical arguments from across several linguistic subdomains in support of the storage of explicit, detailed linguistic tokens, and argues against the storage of abstractions.

My aim in this post is to go over some of Ambridge's main arguments, review a selection of the replies to his target article, and assess the position he settles on in his final rejoinder. In doing this, I'll spend some time talking about what's involved in cashing out (some) approaches to exemplar-based approaches to linguistics acquisition and knowledge, as well as touching on the nature of abstraction in cognition and linguistics broadly, and in phonetics/phonology more specifically, as that is my main area of knowledge.

1. TOC
{:toc}

## _Against stored abstractions: A radical exemplar model of language acquisition_

Ambridge lays out his position clearly in the opening paragraph of his introduction:

> Most, perhaps all, mainstream theories of child language acquisition share a common assumption: adult
> knowledge of language includes stored abstractions such as [VERB] [NOUN] and [SUBJECT], and language
> acquisition therefore involves forming and/or mastering these abstractions. The goal of the present article
> is to argue that this assump- tion is misplaced, and to present the case for a radical alternative: adult
> knowledge of language consists of nothing but stored exemplars and the ability to analogize across them on
> the fly in comprehension or production.1 Child language acquisition therefore involves simply storing these
> exemplars and developing this ability.

Note that although the article title and introductory paragraph specifically call out language
acquisition (Ambridge is, after all, a language acquisition reseacher and the target article appeared
in the journal _First Language_), it is clearly stated that presented model or theory is intended to account
for _adult_ linguistic knowledge in addition to the process of acquisition.

## replies: for, against, and conciliatory

### abstraction is necessary
- Hartshorne
- Schuler et al
- Demuth & Johnson

### deep learning
- Mahowald et al
- McClelland

### phonology
- Finley
- Rose

### predictive failures and definitional quibbles
- Zettersten et al
- Lieven et al

### other good points
- ...

## what is "(linguistic) abstractions"? what are "abstract (linguistic) representations"?

### Hyman

However, what I usually say is that everything in (traditional, structural) phonology is abstract, starting with the phoneme, which after all is just a way of saying that certain concrete realizations are related to each other in a particular way. The same is true, of course, of morphophonemes/morphophonemic analyses, which are designed to capture the relationship between allomorphs. Classical generative phonology looked more "abstract" because morphophonemic analyses allow the representations to diverge further from the phonetic "facts". Rather than derivation, there are those who today would instead favor setting up "less abstract" allomorphs in parallel which are more concretely related to each other. A great example of an abstraction is floating tones. As I always say, "Floating tones are an analysis!" You don't HEAR floating tones. You posit them to capture relations between tones. (See my attached paper if you want more on this.)

(see _"Why underlying representations?!"_ attached to email)

### Hayes

It’s hard to prove abstraction; I think; often analogical models do well in mimicking rule-based models.

One nice category is so-called “Bach testing”:  one tests the pattern with examples that fall outside the legal patterns of the language (work of Steven Pinker). Thus plural of “Bach” has [-s], not [-z] or [@z], reflecting the status of [x] as a voiceless nonsibilant.  I think there should be more Bach testing, it’s underutilized.

### Goldsmith

I would underline the fact that the notion of abstractness in phonology is only well-defined within the context of a particular theory of phonology,
a highly derivational theory of the SPE sort. If we restrict ourselves to that framework, then I think the best discussion of what it means
to be abstract is found in a discussion in two books by Kenstowicz and Kisseberth. I am not sure which one is better on the subject; I think
it's the beginning of the 1977 book, but it is possible that the 1979 book is what I am thinking of. What I remember is a sequence of
hypotheses, each weaker than the preceding one, each of which can be thought of as a possible definition of abstractness which should
be avoided in an analysis. After each formulation, they show that there are strong empirical arguments against such a restriction.

The 1977 book is Topics in Phonological Theory,
the 1979 book is Generative Phonology, description and theory.

### Dresher

The two versions of the question have different answers. As I think of it, "phonological abstraction” is a more general term that applies to just about any theory of phonology. I understand it to mean that we abstract away from the acoustic signal in various ways. For example, the segmentation of speech into discrete segments is an abstraction from the wave form. I don’t think it’s possible to do phonology at all (or even phonetics) without some sort of abstraction of this sort.

The term "abstract phonological representation” has a more specific meaning in the history of phonology. It refers to an underlying (i.e. lexical) phonological representation that is different in certain ways from the surface phonetic representation. How different these representations have to be to count as “abstract” depends on who you ask. Everyone would agree, I think, that positing an underlying segment that never occurs in the surface phonetics of a language would be an example of an abstract representation. A famous example is Chomsky & Halle in The sound pattern of English (SPE) positing an underlying /x/ in some English words. An example is right for which they posit underlying /rixt/. Other cases of abstractness would be positing an underlying form that is “cobbled together” from different allomorphs of a word. E.g. positing /foto-/ as underlying the first part of the words photograph, photography, photographic, even though none of these words show both vowels as having [o] on the surface (in this case there is now a word photo that has two [o]s, but you get the idea). Or positing, as SPE does, that the vowel underlying the second syllable of serene ~ serenity is /eː/, although that vowel does not ever show up in any form of this morpheme.    

So that is how I understand "abstract phonological representation”. The next question is whether such representations can be part of phonological theory, or, as Kiparsky famously asked, How abstract is phonology? My approach to this question is that we should not rely on our own intuitions about how much abstractness is too much, but rather we should follow the evidence that we have. Many people assume that abstract representations are difficult, or impossible, for a learner to acquire. I don’t assume that this is always true. I think it depends on what cognitive principles (which we call Universal Grammar, UG) we think the learner is endowed with. Way back in the early 1980s I wrote two papers defending an abstract analysis of Old English phonology:

Dresher, B. Elan. 1981. Abstractness and Explanation in Phonology. In Norbert Hornstein and David Lightfoot, eds., Explanation in Linguistics: The Logical Problem of Language Acquisition, 76–115. London: Longman.

___. 1981. On the Learnability of Abstract Phonology. In C. L. Baker and John J. McCarthy, eds., The Logical Problem of Language Acquisition, 188–210. Cambridge: MIT Press. Reprinted in Charles W. Kreidler, ed., Phonology: Critical Concepts in Linguistics, Volume 6: Focus on the Speaker, 5–25. London: Routledge, 2001.  

Simplifying a bit, in the first paper I argued that an abstract account is more adequate (more explanatory) than a concrete analysis; in the second one, I tried to show that under certain assumptions about UG this abstract analysis is not at all hard to learn. If we think of segments as being composed of features, then abstract representations become less counter-intuitive. For example, in the case of serene ~ serenity, the surface vowel of the second sylllable alternates between [iː] and [ɛ], that is [+high, -back, +tense] and [-high, -back, -tense]. Assuming the learner wants to come up with a single underlying lexical representation (some exemplar theorists don’t assume this, but I do), the learner has to come up with a set of features that can be realized as both of these, depending on the contexts. The SPE answer is /-high, -back, +tense], that is, taking [-high] from one of the forms and [+tense] from the other, producing a "cobbled together” combination of features that is never pronounced as such, but which amounts to the best solution, in the view of SPE, to this particular problem. In the case of right, SPE wanted to explain why right ~ righteous (with the stressed diphthong [ʌj]) does not pattern like line ~ linear (with stressed [ɪ]). They argue that positing /rixt/ enables them to account for that.

This is not to say that the SPE analyses are correct: the case of /rixt/ has been a special target of anti-abstractness phonologists, and I would agree that in this case SPE does not really show how a learner would arrive at not only the underlying /x/, but the set of rules that involve this /x/ that produce the observed alternations. However, my view is that you can’t just dismiss abstract representations because they look strange or violate what you think learners are able to acquire; you have to provide some learning theory (i.e. UG) to support your opinion.

### Reiss

Sapir has a paper in which he talks about glottalized consonants in Nootka. In obstruents you get preglottalization, whereas in sonorants you get post glottalization. Phoneticians wanted to transcribe the two differently but native speakers found that ridiculous. Basically, Sapir said, the speakers don't care about relative order of the oral and glottal guestures. They abstract away from that aspect of the gestures and treat all glottalized consonants as the same for grammataical purposes.

Another example: Every word a kid hears is in some intonation contour.
You dance
You dance?
Dance!
etc

But a kid must store a representation of the word/morpheme that is DEVOID of intonation, which is something they never hear. Upon hearing "You fax" they can generate "You fax?" and "Fax!" with correct intonation. So they must abstract away from what they hear when they store morphemes in memory. THey NEVER store what they hear.

### Idsardi

I'm adding Phil Monahan to this, as he has been doing some neuro work on the abstract nature of features for a while now, sometimes with me and Mathias Scharinger, but it's his most recent work that I want to emphasize here. He has been looking at linguistic features for things as simple as "voicing" and place of articulation. Briefly, in languages like English, there is no common auditory signal for the "voiced/voiceless" distinction across stops and fricatives. The auditory distinction (in onsets) is VOT in stops but vocal fold vibrations in fricatives. And yet it is possible for speakers to group across this difference between stops and fricative. Frankly, similar considerations hold for place of articulation (the auditory cues are also different across plosives, fricatives, nasals and approximants) and for nasality (different auditory cues for stops and vowels).

I had (what was advertised as) a debate at MFM with Janet Pierrehumbert, but we both ended up saying that abstraction is necessary for generalization (a sort of obvious point), and you can see some of her position in the annual review article, https://www.annualreviews.org/doi/abs/10.1146/annurev-linguistics-030514-125050.

### Monahan

Fred, I have a paper on Mandarin retroflex consonants that should be out in a special collection of Frontiers in Human Neuroscience soon-ish, and the paper Bill is referring to is currently being written—as I type this. I’m happy to discuss either of these with you. Though Bill’s characterization of the latter paper (English voicing) pretty nicely sums up the results.

I was also unfamiliar with the Ambridge paper; I dud take a skim through it after receiving this message yesterday. I focused mostly on the phonetics/phonology section. I also found his rebuttal, where he concedes that abstraction in phonetics/phonology is necessary, but that these abstractions are not stored but computed "on the fly”. It seemed to be a revelation to him that phonetics and phonology have long since understood that both kinds of representations (indexical and abstract) at some level are required—indexical because it doesn’t take long to recognize it’s your mom on the phone and abstract, because as Bill notes, we generalize all over the place. 

### Heinz



### Lev

### Finley

 Ambridge doesn't talk much about phnology in his paper,  but he says that OT is too abstract to handle fine-grained details (which I don't think is correct). In my work, when I have been looking for abstraction, it's mostly focused on phonological features, which certainly vary in abstraction (e.g., CV theory or Government phonology is much more abstract than in grounded phonology), but I think a lot of basic things in phnology would be abstract, like stress, onset/coda, a mora, tiers, underlying forms, and the rules/constraints that apply to them. It is really hard to think about how one could do phonology without abstraction, which is why even exemplar theories have abstraction to some degree.


### Freuhwald

From the domain of language variation & change, there's the phenomenon of what Labov calls the "binding force" in Volume 3 of the principles of language change.

Briefly described, we see a lot of examples of chain shifts, whereby one vowel moves, and an adjacent vowel moves in to the vacated space. For example, in the Inland North, /æ/ moved to a higher, fronter position, allowing the low, back /a/ to front into the vacated space. This could be explicable on exemplar theoretic grounds with lexically based homophony avoidance or something.

But it gets more complicated when allophones become involved. For example, many North American dialects have two very different allophones for /æ/, with a longer, higher, fronter allophone before nasals, and a low frontish allophone elsewhere. However, in none of these dialects has pre-nasal /a/ fronted into the space vacated by pre-nasal /æ/. In principle, /a/ can front into this space, as we see happen when /æ/ raises across the board in the Inland North. 

There is not an easy way with a vanilla, or even a radical, exemplar theory, to explain why pre-nasal /a/ doesn't front in these dialects. If the /a/ in mom were to front, there would be no risk of it being mistaken for ma'am, since that vowel would be much higher and fronter. Yet, there's no evidence that this kind of "allophonic chain shift" happens.

I have my own notion about the kind of abstraction that is involved here, but at the very least, categories like /æ/ and /a/ must exist. At some point, the fronting of mom is blocked because its would be confused for being in the category /æ/, even though it could not be confused for its actual minimal pair ma'am.

### Dunbar

I haven’t read the article, but I read the abstract of the response to reviews. As a preface, the mention of neural networks makes me wonder whether part of the discussion in the exchange might be, in my opinion, beside the point (if I read the article/responses I would know the answer, which I can’t do right now because classes start tomorrow and I tend to get quite absorbed in these things). In particular, I often insist that we all remember there may be multiple ways of seeing the same object (in this case, representation), and that whatever representation we describe with a formalism, be it abstract or other, will necessarily be a embedded in a system that could be described in some other way. To get more concrete, in Marrian terms any representation described at the “computational/representational” level will have some “implementational” level description as well, and, in philosophers’ terms, the higher-level description must necessarily “supervene on” some lower-level state of affairs. It often seems to me that debates become about whether XYZ representation is the “only” reality, as if there were a literal wax tablet on which the actual symbols were engraved in the brain as pictures. That makes no sense. Here is a response piece I wrote a couple of years ago that tried to suss that out:

dunbar__commentary_on_pater__preprint_oct_2018.pdf (utoronto.ca)

That having been said, there are clear distinctions to be made about what kinds of representations one has affair with. One is how many states they can take on, as in the bitrate that we measured in the Zero Resource 2019-2020 challenges:

[1904.11469] The Zero Resource Speech Challenge 2019: TTS without T (arxiv.org)

[2010.05967] The Zero Resource Speech Challenge 2020: Discovering discrete subword and word units (arxiv.org)

That just measures something like “how discrete” the representation is – how little information it contains. The acoustics are rich, phonemic or orthographic representations are information-impaired. By the way, one of the important results of that line of work so far is that phonemic and orthographic representations are almost magically good, given how easy it is to stumble across coherent but useless discrete representations of speech (see the papers). This is somewhat coherent with some work I did with Abdellah Fourtassi a few years ago:

fourtassi_et_al_cogsci_2014_camera_ready.pdf (utoronto.ca)

However, I am not sure one should call this dimension “abstractness”. Maybe more like “richness”. I got told recently by colleague Jessamyn Schertz for calling richness abstractness, and thereby conflating it with “similarity to the acoustics”. You should contact her as well, given that she appears to be clearer-headed than me in this regard. It’s not the same thing. You could have a low bit-rate representation that has phonetically grounded SPE-style features, or a low bit-rate representations that has contentless Hale and Reiss type features. The difference, I guess, would be the complexity of the function relating them to the phonetics.

- views of those who've bothered to reply to my solication
  - CharlesR x
  - Idsardi x
  - Monahan x
  - Heinz
  - Lev
  - Ida
  - Finley x
  - Ewan x 
  - Elan x
  - Hayes x
  - Albright
  - Hyman x
  - Dunbar x
  - Goldsmith x
  - 

### my view

transient, process, linked to generalization, observable, _etc_

## Varieties of exemplar models

blabla

### what is "storage"?

yadda

### what is "analogy"? how does it work?

yadda

### what is "similarity"? where does it come from?

## where do NNs fit in?

BERT, ELMo et al

## incommensurability & foundational premises

map/terrain stuff

- Ambridge's point about Adger's example

## what are we (linguists) trying to do here, anyway?

- modeling in phonology (linguistics): Bradfield paper
- science as sense-making vs "explanation"
- Feyerabend
- "let a thousand flowers bloom"
